{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data\n",
    "data = np.genfromtxt('LinearRegressionData.txt', delimiter = ',')\n",
    "# data = (data - data.mean())/data.std()\n",
    "# np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(data):\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_std = np.std(data, axis=0)\n",
    "        data=(data-data_mean)/data_std\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing random theta\n",
    "data = normalise(data)\n",
    "theta = np.random.randn(3,1)\n",
    "#Training and test set\n",
    "x_train = data[0:35, (0,1)]\n",
    "x_test = data[35:, (0,1)]\n",
    "y_train = data[0:35, 2]\n",
    "y_train = y_train.reshape(35,1)\n",
    "y_test = data[35:, 2]\n",
    "m = len(x_train)\n",
    "ones = np.ones((m, 1))\n",
    " #Adding a ones column matrix \n",
    "x_train = np.hstack((ones, x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(x_train, theta, y_train, m):\n",
    "    y_pred = x_train.dot(theta)\n",
    "    J = np.sum(np.square(y_pred - y_train))/2*m\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gradientDescent(x_train, y_train, theta, m):\n",
    "    y_pred = x_train.dot(theta)\n",
    "    dJ = np.dot((y_pred - y_train).T,x_train)/(m)\n",
    "    alpha = 0.00005\n",
    "    num_of_iter = 10000\n",
    "    for i in range(num_of_iter):\n",
    "        theta = theta - alpha*(dJ.T)\n",
    "    return theta\n",
    "#updating predicted value\n",
    "theta = gradientDescent(x_train, y_train, theta, m)\n",
    "y_pred = x_train.dot(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyPred(y_pred,y_train,theta):\n",
    "    error = (y_pred - y_train)/(y_train) * 100\n",
    "    accuracy = 100 - abs(np.mean(error))\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
