{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data\n",
    "data = np.genfromtxt('Half_kernel.txt', delimiter = ',')\n",
    "np.random.shuffle(data)\n",
    "x = data[:, (0,1)]\n",
    "def normalize(X):\n",
    "        mean=np.mean(X,axis=0)\n",
    "        X=X-mean\n",
    "        return X\n",
    "normalize(x)\n",
    "y = data[:, 2]\n",
    "y = y.reshape(1000, 1)\n",
    "m = len(x)\n",
    "n = len(np.unique(y))\n",
    "x = x.reshape(x.shape[1], m)\n",
    "y = y.reshape(1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    sigZ = 1/(1 + np.exp(-z))\n",
    "    return sigZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerSize(x, y, n):\n",
    "    \n",
    "    n_I = x.shape[0]\n",
    "    n_h1 = 20          #Number of neurons in hidden layer 1 and 2.\n",
    "    n_h2 = 15\n",
    "    n_O = y.shape[0]\n",
    "    \n",
    "    return n_I, n_h1, n_h2, n_O\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialise(n_I, n_h1, n_h2, n_O):\n",
    "    #Weights initialisation\n",
    "    w1 = np.random.randn(n_h1, n_I)*0.01\n",
    "    w2 = np.random.rand(n_h2, n_h1)*0.01\n",
    "    w3 = np.random.randn(n_O, n_h2)*0.01\n",
    "    b1 = np.zeros((n_h1, 1))\n",
    "    b2 = np.zeros((n_h2, 1))\n",
    "    b3 = np.zeros((n_O, 1))\n",
    "    \n",
    "    WandB = {\"w1\": w1, \"w2\": w2, \"w3\": w3,\n",
    "                  \"b1\": b1,\"b2\": b2, \"b3\": b3}\n",
    "    return WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, WandB):\n",
    "    \n",
    "    #Getting the weights and biases\n",
    "    w1 = WandB[\"w1\"]\n",
    "    w2 = WandB[\"w2\"]\n",
    "    w3 = WandB[\"w3\"]\n",
    "    b1 = WandB[\"b1\"]\n",
    "    b2 = WandB[\"b2\"]\n",
    "    b3 = WandB[\"b3\"]\n",
    "    \n",
    "    z1 = np.dot(w1, x) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = np.tanh(z2)\n",
    "    z3 = np.dot(w3, a2) + b3\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    ZandA = {\"z1\": z1, \"z2\": z2, \"z3\": z3,\n",
    "             \"a1\": a1, \"a2\": a2, \"a3\": a3}\n",
    "    return ZandA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y, ZandA, m):\n",
    "    \n",
    "    a3 = ZandA[\"a3\"]\n",
    "    cost = (-1/m)*np.sum( y*np.log(a3) + (1-y)*np.log(1-a3))\n",
    "    \n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(x, y, m, WandB, ZandA):\n",
    "    \n",
    "    #Getting the required weights\n",
    "    w1 = WandB[\"w1\"]\n",
    "    w2 = WandB[\"w2\"]\n",
    "    w3 = WandB[\"w3\"]\n",
    "    \n",
    "    #Getting the required activations and z's\n",
    "    a1 = ZandA[\"a1\"]\n",
    "    a2 = ZandA[\"a2\"]\n",
    "    a3 = ZandA[\"a3\"]\n",
    "    \n",
    "    #Calculating the gradients \n",
    "    dz3 = a3 - y\n",
    "    dw3 = np.dot(dz3, a2.T)/m\n",
    "    db3 = np.sum(dz3, axis = 1, keepdims = True)/m\n",
    "    dz2 = np.dot(w3.T, dz3) * (1 - a2**2)\n",
    "    dw2 = np.dot(dz2, a1.T)/m\n",
    "    db2 = np.sum(dz2, axis = 1, keepdims = True)/m\n",
    "    dz1 = np.dot(w2.T, dz2) * (1 - a1**2)\n",
    "    dw1 = np.dot(dz1, x.T)/m\n",
    "    db1 = np.sum(dz1, axis = 1, keepdims = True)/m\n",
    "    \n",
    "    gradWandB = {\"dw1\": dw1, \"dw2\": dw2,\"dw3\": dw3,\n",
    "             \"db1\": db1, \"db2\": db2, \"db3\": db3}\n",
    "    \n",
    "    return gradWandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWandB(WandB, gradWandB, alpha = 0.005):\n",
    "    \n",
    "    #Getting the weights and biases\n",
    "    w1 = WandB[\"w1\"]\n",
    "    w2 = WandB[\"w2\"]\n",
    "    w3 = WandB[\"w3\"]\n",
    "    b1 = WandB[\"b1\"]\n",
    "    b2 = WandB[\"b2\"]\n",
    "    b3 = WandB[\"b3\"]\n",
    "    \n",
    "    #Getting the gradients of weights and biases\n",
    "    dw1 = gradWandB[\"dw1\"]\n",
    "    dw2 = gradWandB[\"dw2\"]\n",
    "    dw3 = gradWandB[\"dw3\"]\n",
    "    db1 = gradWandB[\"db1\"]\n",
    "    db2 = gradWandB[\"db2\"]\n",
    "    db3 = gradWandB[\"db3\"]\n",
    "       \n",
    "    #Updating the parameters\n",
    "    w1 -= alpha*dw1\n",
    "    w2 -= alpha*dw2\n",
    "    w3 -= alpha*dw3\n",
    "    b1 -= alpha*db1\n",
    "    b2 -= alpha*db2\n",
    "    b3 -= alpha*db3\n",
    "    \n",
    "    updatedWandB = {\"w1\": w1, \"w2\": w2, \"w3\": w3,\n",
    "                  \"b1\": b1,\"b2\": b2, \"b3\": b3}\n",
    "    return updatedWandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetInAction(x, y, n_I, n_h1, n_h2, n_O, num_of_iter = 10000):\n",
    "    \n",
    "    #Getting the weights and biases\n",
    "    WandB = Initialise(n_I, n_h1, n_h2, n_O)\n",
    "\n",
    "    for i in range(0, num_of_iter):\n",
    "         \n",
    "        ZandA = forward_prop(x, WandB)\n",
    "    \n",
    "        cost = cost_function(y, ZandA, m)\n",
    "        \n",
    "        gradWandB = backward_prop(x, y, m, WandB, ZandA)\n",
    "        \n",
    "        WandB = updateWandB(WandB, gradWandB, alpha = 0.9)\n",
    "        if (i % 5000 == 0):\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    return WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, y, n,n_I, n_h1, n_h2, n_O):\n",
    "    \n",
    "    WandB = neuralNetInAction(x, y, n_I, n_h1, n_h2, n_O, num_of_iter = 50000)\n",
    "    ZandA = forward_prop(x, WandB)\n",
    "    a3 = ZandA[\"a3\"]\n",
    "    predictions = np.round(a3)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693148\n",
      "Cost after iteration 5000: 0.636036\n",
      "Cost after iteration 10000: 0.602920\n",
      "Cost after iteration 15000: 0.570878\n",
      "Cost after iteration 20000: 0.571620\n",
      "Cost after iteration 25000: 0.555629\n",
      "Cost after iteration 30000: 0.568304\n",
      "Cost after iteration 35000: 0.584363\n",
      "Cost after iteration 40000: 0.540278\n",
      "Cost after iteration 45000: 0.563580\n"
     ]
    }
   ],
   "source": [
    "n_I, n_h1, n_h2, n_O = layerSize(x, y, n) \n",
    "y_pred = predict(x, y, n, n_I, n_h1, n_h2, n_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.80000000000001"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= (y_pred==y)\n",
    "#         acc=np.mean(a)*100\n",
    "#         return acc\n",
    "np.mean(a) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
